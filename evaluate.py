import gc
import logging
import os
import sys

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import seaborn as sns
import torch
import torch.nn as nn
from sklearn.decomposition import PCA
from sklearn.manifold import TSNE
from tqdm import tqdm

plt.rcParams["font.family"] = "sans-serif"
plt.rcParams["font.sans-serif"] = ["Arial", "DejaVu Sans"]
plt.rcParams["axes.unicode_minus"] = False
sns.set_theme(style="whitegrid", context="talk", font_scale=1.0)

# è“è‰²(æ­£), çº¢è‰²(è´Ÿ), ç°è‰²(èƒŒæ™¯)
COLORS = {
    "pos": "#2E86C1",  # å¼ºè“è‰²
    "neg": "#C0392B",  # æ·±çº¢è‰²
    "bg": "#D5D8DC",  # æµ…ç°è‰²
    "groups": ["#1ABC9C", "#9B59B6", "#F39C12"],  # Top3 ç»„çš„ä¸“å±è‰² (ç»¿, ç´«, æ©™)
}

# ================= âš™ï¸ è·¯å¾„ä¸é…ç½® =================
HARD_TEST_FILE = "dataset/hard_negatives_test.csv"
EASY_TEST_FILE = "dataset/easy_samples_all.csv"
SAVE_DIR = "evaluation_results"  # æ–°ç›®å½•ï¼ŒåŒºåˆ†ä¹‹å‰çš„

BASELINE_CHECKPOINT = "weights/ProTrek_35M/ProTrek_35M.pt"
FINETUNED_CHECKPOINT = "weights/ProTrek_35M/protrek_finetuned_epoch30.pt"

DEVICE = "cuda" if torch.cuda.is_available() else "cpu"

BASE_CONFIG = {
    "protein_config": "weights/ProTrek_35M/esm2_t12_35M_UR50D",
    "text_config": "weights/ProTrek_35M/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext",
    "structure_config": "weights/ProTrek_35M/foldseek_t12_35M",
}

sys.path.append("./ProTrek")
from model.ProTrek.protrek_trimodal_model import ProTrekTrimodalModel

logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(message)s")
logger = logging.getLogger(__name__)

if not os.path.exists(SAVE_DIR):
    os.makedirs(SAVE_DIR)


# ================= ğŸ› ï¸ æ ¸å¿ƒå·¥å…·å‡½æ•° =================


def load_model(checkpoint_path):
    config = BASE_CONFIG.copy()
    config["from_checkpoint"] = checkpoint_path
    logger.info(f"Loading: {checkpoint_path}")
    return ProTrekTrimodalModel(**config).eval().to(DEVICE)


def get_scores_and_embeddings(model, df):
    """
    è®¡ç®—æ‰€æœ‰æ ·æœ¬çš„åˆ†æ•°ï¼Œå¹¶è¿”å› Embeddings ä»¥ä¾¿åç»­ç­›é€‰
    """
    pos_scores = []
    neg_scores = []
    embeddings = {"anchor": [], "text": [], "hard_neg": []}

    with torch.no_grad():
        for _, row in tqdm(df.iterrows(), total=len(df), desc="Inference"):
            a_emb = model.get_protein_repr([row["anchor_seq"]])
            t_emb = model.get_text_repr([row["anchor_text"]])
            n_emb = model.get_protein_repr([row["hard_neg_seq"]])

            # è½¬æ¢ä¸º Numpy
            a_np = a_emb.cpu().numpy()
            t_np = t_emb.cpu().numpy()
            n_np = n_emb.cpu().numpy()

            # è®¡ç®—åˆ†æ•°
            s_pos = np.sum(a_np * t_np)
            s_neg = np.sum(n_np * t_np)

            pos_scores.append(s_pos)
            neg_scores.append(s_neg)

            embeddings["anchor"].append(a_np)
            embeddings["text"].append(t_np)
            embeddings["hard_neg"].append(n_np)

    return np.array(pos_scores), np.array(neg_scores), embeddings


# ================= ğŸ“Š ç»˜å›¾å‡½æ•° =================


def plot_bar_chart_pro(acc_data):
    """
    å›¾ 1: å‡†ç¡®ç‡å¯¹æ¯” (æç®€é£)
    """
    logger.info("Plotting Pro Bar Chart...")
    plt.figure(figsize=(7, 6))

    df = pd.DataFrame(acc_data)

    # ç»˜åˆ¶æŸ±çŠ¶å›¾
    ax = sns.barplot(
        data=df,
        x="Dataset",
        y="Accuracy",
        hue="Model",
        palette=[COLORS["bg"], COLORS["pos"]],
        edgecolor=".2",
    )

    sns.despine(top=True, right=True)
    plt.ylim(0, 110)
    plt.ylabel("Accuracy (%)", fontweight="bold")
    plt.xlabel("")
    plt.title("Model Performance Improvement", fontweight="bold", pad=20)
    plt.legend(frameon=False, loc="upper left", markerscale=0.5, fontsize="x-small")
    plt.grid(axis="y", linestyle="--", alpha=0.5)

    # æ ‡æ³¨æ•°å€¼
    for container in ax.containers:
        ax.bar_label(container, fmt="%.1f%%", padding=3, fontweight="bold")

    plt.tight_layout()
    plt.savefig(os.path.join(SAVE_DIR, "1_accuracy_comparison.png"), dpi=300)
    plt.close()


def plot_kde_pro(base_scores, ft_scores):
    """
    å›¾ 2: åˆ†æ•°åˆ†å¸ƒ
    """
    logger.info("Plotting Pro KDE...")
    fig, axes = plt.subplots(1, 2, figsize=(14, 6), sharey=True)

    # Helper to plot one subplot
    def draw_kde(ax, pos, neg, title):
        sns.kdeplot(
            pos,
            ax=ax,
            fill=True,
            color=COLORS["pos"],
            alpha=0.3,
            linewidth=2,
            label="Positive Pair",
        )
        sns.kdeplot(
            neg,
            ax=ax,
            fill=True,
            color=COLORS["neg"],
            alpha=0.3,
            linewidth=2,
            label="Negative Pair",
        )
        ax.set_title(title, fontweight="bold", fontsize=14)
        ax.set_xlabel("Similarity Score")
        ax.grid(linestyle=":", alpha=0.6)
        sns.despine(ax=ax)

    draw_kde(
        axes[0], base_scores["pos"], base_scores["neg"], "Baseline Model (Confused)"
    )
    draw_kde(axes[1], ft_scores["pos"], ft_scores["neg"], "Finetuned Model (Separated)")

    axes[0].legend(frameon=False, loc="upper left")

    plt.suptitle(
        "Score Distribution Shift on Hard Negatives", fontweight="bold", y=0.97
    )
    plt.tight_layout()
    plt.savefig(os.path.join(SAVE_DIR, "2_score_distribution.png"), dpi=300)
    plt.close()


def plot_focused_tsne(base_emb, ft_emb, top_indices):
    logger.info("Plotting Focused t-SNE...")

    # å‡†å¤‡èƒŒæ™¯æ•°æ®
    n_bg = 50
    bg_indices = np.random.choice(len(base_emb["text"]), n_bg, replace=False)

    # å‡†å¤‡ Top 3 æ•°æ®
    target_indices = top_indices

    # åˆå¹¶ç´¢å¼•
    all_indices = list(set(list(bg_indices) + list(target_indices)))

    fig, axes = plt.subplots(1, 2, figsize=(18, 9))

    for i, (emb_dict, title) in enumerate(
        [(base_emb, "Baseline Space"), (ft_emb, "Finetuned Space")]
    ):
        ax = axes[i]

        # 1. æ”¶é›†è¿™ä¸€è½®è¦ç”»çš„æ‰€æœ‰å‘é‡
        vectors = []
        labels = []  # ç”¨æ¥æ ‡è®°å±äºå“ªä¸ªç»„

        # ç»“æ„ï¼š[Text_1...Text_N, Anchor_1...Anchor_N, Neg_1...Neg_N]
        for idx in all_indices:
            vectors.append(emb_dict["text"][idx].flatten())
            vectors.append(emb_dict["anchor"][idx].flatten())
            vectors.append(emb_dict["hard_neg"][idx].flatten())

        vectors = np.array(vectors)

        # 2. é™ç»´ (PCA åˆå§‹åŒ– + t-SNE å¾®è°ƒï¼Œä¿è¯ç»“æ„ç¨³å®š)
        reducer = TSNE(
            n_components=2, perplexity=10, random_state=42, init="pca", learning_rate=50
        )
        embedded = reducer.fit_transform(vectors)

        # 3. ç»˜å›¾
        n_samples = len(all_indices)

        # A. å…ˆç”»èƒŒæ™¯ (ç°è‰²ï¼Œé€æ˜)
        # åæ ‡æ˜ å°„: index j å¯¹åº” embedded ä¸­çš„ [3*j, 3*j+1, 3*j+2]
        for j, list_idx in enumerate(all_indices):
            if list_idx in target_indices:
                continue  # è·³è¿‡ Top 3ï¼Œæœ€åç”»

            t_xy = embedded[3 * j]
            a_xy = embedded[3 * j + 1]
            n_xy = embedded[3 * j + 2]

            # ç”»ç‚¹
            ax.scatter(t_xy[0], t_xy[1], c=COLORS["bg"], s=30, alpha=0.3)
            ax.scatter(a_xy[0], a_xy[1], c=COLORS["bg"], s=30, alpha=0.3)
            ax.scatter(n_xy[0], n_xy[1], c=COLORS["bg"], s=30, alpha=0.3)

        # B. å†ç”» Top 3 (é«˜äº®ï¼Œå¸¦è¿çº¿)
        legend_elements = []  # æ‰‹åŠ¨å›¾ä¾‹

        for k, target_idx in enumerate(target_indices):
            # æ‰¾åˆ° target_idx åœ¨ all_indices ä¸­çš„ä½ç½®
            j = all_indices.index(target_idx)

            t_xy = embedded[3 * j]
            a_xy = embedded[3 * j + 1]
            n_xy = embedded[3 * j + 2]

            group_color = COLORS["groups"][k]

            # ç”»è¿çº¿ (è™šçº¿)
            ax.plot(
                [t_xy[0], a_xy[0]],
                [t_xy[1], a_xy[1]],
                color=group_color,
                linestyle="-",
                alpha=0.6,
                linewidth=1.5,
            )
            ax.plot(
                [t_xy[0], n_xy[0]],
                [t_xy[1], n_xy[1]],
                color=group_color,
                linestyle="--",
                alpha=0.6,
                linewidth=1.5,
            )

            # ç”»ç‚¹ (Text=æ˜Ÿå½¢, Anchor=åœ†å½¢, Neg=å‰å½¢)
            ax.scatter(
                t_xy[0],
                t_xy[1],
                color=group_color,
                marker="*",
                s=300,
                edgecolor="white",
                label="Text" if k == 0 else "",
                zorder=10,
            )
            ax.scatter(
                a_xy[0],
                a_xy[1],
                color=group_color,
                marker="o",
                s=150,
                edgecolor="white",
                label="Anchor" if k == 0 else "",
                zorder=10,
            )
            ax.scatter(
                n_xy[0],
                n_xy[1],
                color=group_color,
                marker="X",
                s=150,
                edgecolor="white",
                label="Hard Neg" if k == 0 else "",
                zorder=10,
            )

            # æ ‡æ³¨ç»„å·
            ax.text(
                t_xy[0],
                t_xy[1] + 0.5,
                f"Case {k + 1}",
                fontsize=12,
                fontweight="bold",
                color=group_color,
                ha="center",
            )

        ax.set_title(title, fontweight="bold", fontsize=16)
        ax.set_xticks([])
        ax.set_yticks([])
        sns.despine(left=True, bottom=True)

        if i == 0:
            # è‡ªå®šä¹‰å›¾ä¾‹
            from matplotlib.lines import Line2D

            custom_lines = [
                Line2D([0], [0], color="gray", linestyle="-"),
                Line2D([0], [0], color="gray", linestyle="--"),
            ]
            ax.legend(
                custom_lines,
                ["Text-Anchor (Should be Close)", "Text-Negative (Should be Far)"],
                loc="lower left",
                fontsize=10,
            )

    plt.suptitle(
        "Embedding Space Evolution (Focus on Top-3 Improved Cases)",
        fontweight="bold",
        y=0.95,
    )
    plt.tight_layout()
    plt.savefig(os.path.join(SAVE_DIR, "3_tsne_top3_focus.png"), dpi=300)
    plt.close()


# ================= ğŸš€ ä¸»ç¨‹åº =================


def main():
    logger.info(">>> Starting Pro Evaluation Pipeline <<<")

    # 1. å‡†å¤‡æ•°æ®
    if not os.path.exists(HARD_TEST_FILE):
        logger.error("Data file not found!")
        return

    df_hard = pd.read_csv(HARD_TEST_FILE)
    df_easy = pd.read_csv(EASY_TEST_FILE)

    # 2. è¿è¡Œ Baseline
    model_base = load_model(BASELINE_CHECKPOINT)

    # è®¡ç®— Hard çš„åˆ†æ•°å’Œ Embedding (ç”¨äº t-SNE)
    h_base_pos, h_base_neg, h_base_emb = get_scores_and_embeddings(model_base, df_hard)
    # è®¡ç®— Easy çš„åˆ†æ•° (åªç”¨äº Bar Chart)
    e_base_pos, e_base_neg, _ = get_scores_and_embeddings(model_base, df_easy)

    del model_base
    torch.cuda.empty_cache()

    # 3. è¿è¡Œ Finetuned
    model_ft = load_model(FINETUNED_CHECKPOINT)

    h_ft_pos, h_ft_neg, h_ft_emb = get_scores_and_embeddings(model_ft, df_hard)
    e_ft_pos, e_ft_neg, _ = get_scores_and_embeddings(model_ft, df_easy)

    del model_ft
    torch.cuda.empty_cache()

    # 4. è®¡ç®—å‡†ç¡®ç‡
    def calc_acc(p, n):
        return np.mean(p > n) * 100

    results = [
        {
            "Model": "Baseline",
            "Dataset": "Hard Samples",
            "Accuracy": calc_acc(h_base_pos, h_base_neg),
        },
        {
            "Model": "Finetuned",
            "Dataset": "Hard Samples",
            "Accuracy": calc_acc(h_ft_pos, h_ft_neg),
        },
        {
            "Model": "Baseline",
            "Dataset": "Easy Samples",
            "Accuracy": calc_acc(e_base_pos, e_base_neg),
        },
        {
            "Model": "Finetuned",
            "Dataset": "Easy Samples",
            "Accuracy": calc_acc(e_ft_pos, e_ft_neg),
        },
    ]

    margin_base = h_base_pos - h_base_neg
    margin_ft = h_ft_pos - h_ft_neg
    improvement = margin_ft - margin_base

    # è·å–å‰3åçš„ç´¢å¼•
    top_3_indices = np.argsort(improvement)[-3:]
    logger.info(f"Top 3 Improved Indices: {top_3_indices}")

    logger.info("--- Generating Plots ---")

    plot_bar_chart_pro(results)

    # ä»…ä½¿ç”¨ Hard æ ·æœ¬ç”»åˆ†å¸ƒå›¾
    score_data_base = {"pos": h_base_pos, "neg": h_base_neg}
    score_data_ft = {"pos": h_ft_pos, "neg": h_ft_neg}
    plot_kde_pro(score_data_base, score_data_ft)

    # ç”»èšç„¦ç‰ˆ t-SNE
    plot_focused_tsne(h_base_emb, h_ft_emb, top_3_indices)

    logger.info(f"Done! Check results in {SAVE_DIR}")


if __name__ == "__main__":
    main()
